{"cells":[{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","from sklearn.experimental import enable_iterative_imputer\n","from sklearn.impute import IterativeImputer\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.feature_extraction.text import TfidfVectorizer"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Fill Missing Courses"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["df = pd.read_csv('../data/course_cleaned.csv', header=0, encoding='unicode_escape')"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["def append_missing_course(df):\n","    # Get distinct values of 'Term' and 'Course Yr'\n","    distinct_terms = df['Term'].unique()\n","    distinct_course_yrs = df['Term Yr'].unique()\n","    # Generate new dataframe with missing distinct courses\n","    new_rows = []\n","    for term in distinct_terms:\n","        for course_yr in distinct_course_yrs:\n","            distinct_courses = df[(df['Term'] == term)]['Course'].unique()\n","            courses = df[(df['Term'] == term) & (df['Term Yr'] == course_yr)]['Course'].unique()\n","            missing_courses = np.setdiff1d(distinct_courses, courses)\n","            for missing_course in missing_courses:\n","                selected_row = df[df['Course'] == missing_course]\n","                new_rows.append({\n","                    'Term': term,\n","                    'Term Yr': course_yr,\n","                    'Course': missing_course,\n","                    'Class Yr': selected_row['Class Yr'].values[0],\n","                    'Dept Desc': selected_row['Dept Desc'].values[0],\n","                    'Cap': np.nan,\n","                    'Enrolled': np.nan\n","                })\n","\n","    new_df = pd.DataFrame(new_rows)\n","    # Concatenate the original dataframe with the new dataframe\n","    courses_df = pd.concat([df, new_df], ignore_index=True)\n","    return courses_df"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["courses = append_missing_course(df)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Impute and Transform Data"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["cat_cols = courses.select_dtypes(include=['object']).columns"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["def transform_data(courses_df):\n","    # create a pipeline to impute missing values with the mean and scale numeric features\n","    numeric_pipeline = Pipeline([\n","        ('scaler', StandardScaler())\n","    ])\n","\n","    # create a pipeline to impute missing values with the most frequent value and one-hot encode categorical features\n","    categorical_pipeline = Pipeline([\n","        ('encoder', OrdinalEncoder())\n","    ])\n","\n","    # create a column transformer to apply the numeric and categorical pipelines to the correct features\n","    # use remainder='passthrough' to keep the remaining features in the dataframe\n","    column_transformer = ColumnTransformer([\n","        ('numeric_transformer', numeric_pipeline, ['Class Yr']),\n","        ('categorical_transformer', categorical_pipeline, cat_cols)\n","    ], remainder='passthrough',verbose_feature_names_out=False)\n","\n","    # fit_transform the preprocessor on the penguins dataset\n","    # convert the result to a dataframe\n","    # use the preprocessor's get_feature_names_out() method to get the column names\n","    transformed_data = column_transformer.fit_transform(courses_df)\n","    transformed_df = pd.DataFrame(transformed_data, columns=column_transformer.get_feature_names_out())\n","\n","    imputer = IterativeImputer(max_iter=10, random_state=0)\n","    transformed_df = pd.DataFrame(np.round(imputer.fit_transform(transformed_df)), columns=transformed_df.columns)\n","    df_prepared = transformed_df.copy()\n","    df_prepared[cat_cols] = column_transformer.named_transformers_['categorical_transformer'].inverse_transform(transformed_df[cat_cols])\n","    df_prepared['Class Yr'] =  column_transformer.named_transformers_['numeric_transformer'].inverse_transform(transformed_df[['Class Yr']]).astype(int)\n","    df_prepared['Class Yr'] = df_prepared['Class Yr'].replace(2, 3)\n","    df_prepared['Class Yr'] = df_prepared['Class Yr'].replace(1, 2)\n","    df_prepared['Class Yr'] = df_prepared['Class Yr'].replace(0, 1)\n","    df_prepared['Term Yr'] = df_prepared['Term Yr'].astype(int)\n","    return df_prepared\n"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["def compute_tfidf_scores(title):\n","    tfidf_vectorizer = TfidfVectorizer()\n","    tfidf_scores = tfidf_vectorizer.fit_transform(title)\n","    summed_scores = tfidf_scores.sum(axis=1)\n","    return summed_scores"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/bhavy/anaconda3/envs/py310/lib/python3.10/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n","  warnings.warn(\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Class Yr</th>\n","      <th>Course</th>\n","      <th>Term</th>\n","      <th>Dept Desc</th>\n","      <th>Term Yr</th>\n","      <th>Cap</th>\n","      <th>Enrolled</th>\n","      <th>TF_IDF</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>CSC 111</td>\n","      <td>Fall</td>\n","      <td>Computer Science</td>\n","      <td>2019</td>\n","      <td>400.0</td>\n","      <td>346.0</td>\n","      <td>1.999486</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>CSC 115</td>\n","      <td>Fall</td>\n","      <td>Computer Science</td>\n","      <td>2019</td>\n","      <td>150.0</td>\n","      <td>130.0</td>\n","      <td>1.714037</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>CSC 115</td>\n","      <td>Summer</td>\n","      <td>Computer Science</td>\n","      <td>2019</td>\n","      <td>115.0</td>\n","      <td>86.0</td>\n","      <td>1.714037</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2</td>\n","      <td>CSC 225</td>\n","      <td>Fall</td>\n","      <td>Computer Science</td>\n","      <td>2019</td>\n","      <td>215.0</td>\n","      <td>197.0</td>\n","      <td>1.727549</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","      <td>CSC 225</td>\n","      <td>Summer</td>\n","      <td>Computer Science</td>\n","      <td>2019</td>\n","      <td>145.0</td>\n","      <td>63.0</td>\n","      <td>1.727549</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>215</th>\n","      <td>3</td>\n","      <td>SENG 310</td>\n","      <td>Spring</td>\n","      <td>Engineering &amp; Computer Science</td>\n","      <td>2022</td>\n","      <td>121.0</td>\n","      <td>106.0</td>\n","      <td>1.684129</td>\n","    </tr>\n","    <tr>\n","      <th>216</th>\n","      <td>3</td>\n","      <td>SENG 321</td>\n","      <td>Spring</td>\n","      <td>Engineering &amp; Computer Science</td>\n","      <td>2022</td>\n","      <td>118.0</td>\n","      <td>105.0</td>\n","      <td>1.377659</td>\n","    </tr>\n","    <tr>\n","      <th>217</th>\n","      <td>3</td>\n","      <td>SENG 371</td>\n","      <td>Spring</td>\n","      <td>Engineering &amp; Computer Science</td>\n","      <td>2022</td>\n","      <td>111.0</td>\n","      <td>101.0</td>\n","      <td>1.412918</td>\n","    </tr>\n","    <tr>\n","      <th>218</th>\n","      <td>4</td>\n","      <td>SENG 401</td>\n","      <td>Spring</td>\n","      <td>Engineering &amp; Computer Science</td>\n","      <td>2022</td>\n","      <td>106.0</td>\n","      <td>96.0</td>\n","      <td>2.221457</td>\n","    </tr>\n","    <tr>\n","      <th>219</th>\n","      <td>4</td>\n","      <td>CSC 460</td>\n","      <td>Spring</td>\n","      <td>Computer Science</td>\n","      <td>2023</td>\n","      <td>140.0</td>\n","      <td>112.0</td>\n","      <td>1.730833</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>220 rows Ã— 8 columns</p>\n","</div>"],"text/plain":["     Class Yr    Course    Term                       Dept Desc  Term Yr  \\\n","0           1   CSC 111    Fall                Computer Science     2019   \n","1           1   CSC 115    Fall                Computer Science     2019   \n","2           1   CSC 115  Summer                Computer Science     2019   \n","3           2   CSC 225    Fall                Computer Science     2019   \n","4           2   CSC 225  Summer                Computer Science     2019   \n","..        ...       ...     ...                             ...      ...   \n","215         3  SENG 310  Spring  Engineering & Computer Science     2022   \n","216         3  SENG 321  Spring  Engineering & Computer Science     2022   \n","217         3  SENG 371  Spring  Engineering & Computer Science     2022   \n","218         4  SENG 401  Spring  Engineering & Computer Science     2022   \n","219         4   CSC 460  Spring                Computer Science     2023   \n","\n","       Cap  Enrolled    TF_IDF  \n","0    400.0     346.0  1.999486  \n","1    150.0     130.0  1.714037  \n","2    115.0      86.0  1.714037  \n","3    215.0     197.0  1.727549  \n","4    145.0      63.0  1.727549  \n","..     ...       ...       ...  \n","215  121.0     106.0  1.684129  \n","216  118.0     105.0  1.377659  \n","217  111.0     101.0  1.412918  \n","218  106.0      96.0  2.221457  \n","219  140.0     112.0  1.730833  \n","\n","[220 rows x 8 columns]"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["# impute data and convert \n","course_prepared = transform_data(courses)\n","course_prepared['TF_IDF'] = compute_tfidf_scores(course_prepared['Title'])\n","course_prepared.drop(columns='Title', inplace=True,axis=1)\n","course_prepared"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["course_prepared = course_prepared.reindex(columns=['Course','TF_IDF','Term','Term Yr','Class Yr','Dept Desc','Cap','Enrolled'])\n","course_prepared.to_csv('../data/course_prepared.csv', index=False)"]}],"metadata":{"deepnote_notebook_id":"600e5efc-406f-4b6a-a04a-bb445176cd4b","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
